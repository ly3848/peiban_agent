app:
  description: 'AIä¼´ä¾£ä¸»å¯¹è¯æµç¨‹ - å®Œæ•´çš„è·¯ç”±+å¯¹è¯+è´¨æ£€å·¥ä½œæµ(é›†æˆ5ä¸ªæ¨¡å—)'
  icon: ğŸš€
  icon_background: '#8b5cf6'
  mode: workflow
  name: 00-main-conversation-flow
  use_icon_as_answer_icon: false
dependencies: []
kind: app
version: 0.3.0
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      enabled: false
    opening_statement: 'ä½ å¥½!æˆ‘æ˜¯ä½ çš„AIä¼´ä¾£,æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—?'
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions:
      - 'æ—©å®‰,ä»Šå¤©æ€ä¹ˆæ ·?'
      - 'æˆ‘æœ€è¿‘æœ‰ç‚¹ç´¯'
      - 'ç»™æˆ‘è®²ä¸ªç¬‘è¯'
    suggested_questions_after_answer:
      enabled: true
    text_to_speech:
      enabled: false
  graph:
    edges:
    # Start â†’ Router
    - data:
        isInIteration: false
        sourceType: start
        targetType: llm
      id: start-to-router
      source: start
      sourceHandle: source
      target: llm-router
      targetHandle: target
      type: custom

    # Router â†’ Parser
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: router-to-parser
      source: llm-router
      sourceHandle: source
      target: code-parser
      targetHandle: target
      type: custom

    # Parser â†’ Route Branch
    - data:
        isInIteration: false
        sourceType: code
        targetType: if-else
      id: parser-to-branch
      source: code-parser
      sourceHandle: source
      target: route-branch
      targetHandle: target
      type: custom

    # Fast Route: Router â†’ E_Sensor1
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: route-fast-to-sensor1
      source: route-branch
      sourceHandle: fast
      target: fast-emotion-sensor1
      targetHandle: target
      type: custom

    # Fast Route: E_Sensor1 â†’ Simple Chat
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: fast-sensor1-to-chat
      source: fast-emotion-sensor1
      sourceHandle: source
      target: fast-simple-chat
      targetHandle: target
      type: custom

    # Fast Route: Simple Chat â†’ Fast Critic
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: fast-chat-to-critic
      source: fast-simple-chat
      sourceHandle: source
      target: fast-critic
      targetHandle: target
      type: custom

    # Fast Route: Fast Critic â†’ Check Pass
    - data:
        isInIteration: false
        sourceType: llm
        targetType: if-else
      id: fast-critic-to-check
      source: fast-critic
      sourceHandle: source
      target: fast-check-pass
      targetHandle: target
      type: custom

    # Fast Route: Pass â†’ Merge Response
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: code
      id: fast-pass-to-merge
      source: fast-check-pass
      sourceHandle: 'true'
      target: merge-response
      targetHandle: target
      type: custom

    # Fast Route: Retry â†’ Merge Response
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: fast-retry-to-merge
      source: fast-simple-chat-retry
      sourceHandle: source
      target: merge-response
      targetHandle: target
      type: custom

    # Smart Route: Pass â†’ Merge Response
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: code
      id: smart-pass-to-merge
      source: smart-check-quality
      sourceHandle: 'true'
      target: merge-response
      targetHandle: target
      type: custom

    # Smart Route: Retry â†’ Merge Response
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: smart-retry-to-merge
      source: smart-emotional-chat-retry
      sourceHandle: source
      target: merge-response
      targetHandle: target
      type: custom

    # VIP Route: VIP Chat â†’ Merge Response
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: vip-chat-to-merge
      source: vip-emotional-chat
      sourceHandle: source
      target: merge-response
      targetHandle: target
      type: custom

    # Merge Response â†’ Final Critic
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: merge-to-final-critic
      source: merge-response
      sourceHandle: source
      target: final-critic
      targetHandle: target
      type: custom

    # Smart Route: Router â†’ E_Sensor2
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: route-smart-to-sensor2
      source: route-branch
      sourceHandle: smart
      target: smart-emotion-sensor2
      targetHandle: target
      type: custom

    # Smart Route: E_Sensor2 â†’ Memory Retrieval
    - data:
        isInIteration: false
        sourceType: llm
        targetType: knowledge-retrieval
      id: smart-sensor2-to-memory
      source: smart-emotion-sensor2
      sourceHandle: source
      target: smart-memory-retrieval
      targetHandle: target
      type: custom

    # Smart Route: Memory â†’ Orchestrator
    - data:
        isInIteration: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: smart-memory-to-orchestrator
      source: smart-memory-retrieval
      sourceHandle: source
      target: smart-orchestrator
      targetHandle: target
      type: custom

    # Smart Route: Orchestrator â†’ Emotional Chat
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: smart-orchestrator-to-chat
      source: smart-orchestrator
      sourceHandle: source
      target: smart-emotional-chat
      targetHandle: target
      type: custom

    # Smart Route: Emotional Chat â†’ Smart Critic
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: smart-chat-to-critic
      source: smart-emotional-chat
      sourceHandle: source
      target: smart-critic
      targetHandle: target
      type: custom

    # Smart Route: Smart Critic â†’ Check Pass
    - data:
        isInIteration: false
        sourceType: llm
        targetType: if-else
      id: smart-critic-to-check
      source: smart-critic
      sourceHandle: source
      target: smart-check-quality
      targetHandle: target
      type: custom

    # Fast Route: Fail â†’ Retry
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: fast-fail-to-retry
      source: fast-check-pass
      sourceHandle: 'false'
      target: fast-simple-chat-retry
      targetHandle: target
      type: custom

    # Smart Route: Fail â†’ Retry
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: smart-fail-to-retry
      source: smart-check-quality
      sourceHandle: 'false'
      target: smart-emotional-chat-retry
      targetHandle: target
      type: custom

    # VIP Route: Router â†’ VIP Chat
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: route-vip-to-chat
      source: route-branch
      sourceHandle: vip
      target: vip-emotional-chat
      targetHandle: target
      type: custom

    # Final Critic â†’ Answer
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: final-critic-to-answer
      source: final-critic
      sourceHandle: source
      target: answer
      targetHandle: target
      type: custom

    nodes:
    # START NODE
    - data:
        desc: 'ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯ä¸Šä¸‹æ–‡'
        selected: false
        title: å¼€å§‹
        type: start
        variables:
        - label: 'ç”¨æˆ·è¾“å…¥'
          max_length: 2000
          options: []
          required: true
          type: text-input
          variable: user_input
        - label: 'ç”¨æˆ·ID'
          max_length: 100
          options: []
          required: true
          type: text-input
          variable: user_id
        - label: 'ç”¨æˆ·å'
          max_length: 50
          options: []
          required: false
          type: text-input
          variable: user_name
        - label: 'ä¼´ä¾£å'
          max_length: 50
          options: []
          required: false
          type: text-input
          variable: companion_name
        - label: 'äººæ ¼æè¿°'
          max_length: 500
          options: []
          required: false
          type: paragraph
          variable: personality_description
        - label: 'æ˜¯å¦VIP'
          options:
          - 'true'
          - 'false'
          required: true
          type: select
          variable: is_vip
        - label: 'å¯¹è¯å†å²(JSON)'
          max_length: 5000
          options: []
          required: false
          type: paragraph
          variable: conversation_history
      height: 280
      id: start
      position:
        x: 30
        y: 200
      positionAbsolute:
        x: 30
        y: 200
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ROUTER NODE
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: 'åˆ†æç”¨æˆ·æ„å›¾å¹¶è¾“å‡ºè·¯ç”±å†³ç­–'
        model:
          completion_params:
            temperature: 0.3
            max_tokens: 500
            response_format: 'json_object'
          mode: chat
          name: deepseek-chat
          provider: deepseek
        prompt_template:
        - id: system-prompt
          role: system
          text: |
            ## ç³»ç»Ÿè§’è‰²
            ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ„å›¾è¯†åˆ«ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·è¾“å…¥,åˆ¤æ–­åº”è¯¥ç”¨å“ªç§å¤„ç†æ–¹å¼ã€‚

            ## ä»»åŠ¡
            åˆ†æç”¨æˆ·çš„è¾“å…¥,å¹¶è¾“å‡ºä»¥ä¸‹JSON:
            {
              "route": "fast|smart|vip",
              "intent": "ç®€çŸ­æè¿°ç”¨æˆ·æ„å›¾",
              "confidence": 0.0-1.0,
              "reasoning": "ä¸ºä»€ä¹ˆåšè¿™ä¸ªåˆ¤æ–­"
            }

            ## è·¯ç”±è§„åˆ™ (ä¼˜å…ˆçº§ä»é«˜åˆ°ä½)

            ### è§„åˆ™1: VIPç”¨æˆ·æ£€æµ‹ (æœ€é«˜ä¼˜å…ˆçº§)
            å¦‚æœ ç”¨æˆ·æ˜¯VIPä¸”è¾“å…¥åŒ…å«å¿ƒç†å’¨è¯¢/äº²å¯†æ¨¡å¼å…³é”®è¯:
              â†’ route = "vip"
              â†’ intent = "emotional_coaching" æˆ– "intimacy_mode"
            å…³é”®è¯ç¤ºä¾‹:
              - å¿ƒç†å’¨è¯¢: "æˆ‘å¾ˆç„¦è™‘", "æˆ‘æŠ‘éƒäº†", "æˆ‘æœ‰å¿ƒç†é—®é¢˜"

            ### è§„åˆ™2: å¤æ‚æ€§è¯„ä¼°
            if è¾“å…¥åŒ…å«ä»¥ä¸‹ç‰¹å¾ â†’ route = "smart":
              - éœ€è¦å¤šæ­¥æ¨ç† (å¦‚: "å¸®æˆ‘è®¡åˆ’...", "æé†’æˆ‘...")
              - éœ€è¦è°ƒç”¨å·¥å…· (å¦‚: "è®¾ç½®æé†’", "æŸ¥è¯¢å¤©æ°”")
              - éœ€è¦è®°å¿†æ£€ç´¢ (å¦‚: "æˆ‘å“¥å“¥å«ä»€ä¹ˆ", "ä½ è®°å¾—...")
              - æœ‰æ˜æ˜¾æƒ…ç»ªå€¾è¯‰ (å¦‚: "æˆ‘å¥½ç´¯", "å¿ƒæƒ…ä¸å¥½")
              - è¾“å…¥é•¿åº¦>30å­— ä¸”åŒ…å«å¤šä¸ªå®ä½“

            ### è§„åˆ™3: ç®€å•é—²èŠ
            else â†’ route = "fast"
            ç‰¹å¾:
              - ç®€å•é—®å€™ ("æ—©å®‰", "æ™šå®‰", "åœ¨å—")
              - å•ä¸€æƒ…ç»ªæ ‡ç­¾ ("å¼€å¿ƒ", "æœ‰ç‚¹çƒ¦")
              - é•¿åº¦<20å­—
              - ä¸éœ€è¦ä¸Šä¸‹æ–‡ç†è§£

            ## è¯„åˆ†é€»è¾‘
            confidence = 0.0-1.0
            - 1.0: éå¸¸ç¡®å®š (å‘½ä¸­å¤šæ¡è§„åˆ™)
            - 0.8+: ç¡®å®š (å‘½ä¸­ä¸»è¦è§„åˆ™)
            - 0.6-0.8: ä¸­ç­‰ (è§„åˆ™å†²çª,éœ€è¦LLMåˆ¤æ–­)
            - <0.6: ä¸ç¡®å®š (éœ€è¦fallbackåˆ°fast)
        - id: user-prompt
          role: user
          text: |
            ç°åœ¨,åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥:
            ç”¨æˆ·è¾“å…¥: {{#start.user_input#}}
            ç”¨æˆ·ä¿¡æ¯:
            - ç”¨æˆ·ID: {{#start.user_id#}}
            - æ˜¯å¦VIP: {{#start.is_vip#}}
            - å¯¹è¯å†å²: {{#start.conversation_history#}}

            è¾“å‡ºJSON:
        selected: false
        title: è·¯ç”±å†³ç­–LLM
        type: llm
        vision:
          configs:
            detail: high
          enabled: false
      height: 98
      id: llm-router
      position:
        x: 350
        y: 200
      positionAbsolute:
        x: 350
        y: 200
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # PARSER NODE
    - data:
        code: |
          import json
          import re

          def main(llm_output: str) -> dict:
              """è§£æLLMè¾“å‡ºçš„JSONå¹¶è¿”å›è·¯ç”±ç»“æœ"""
              try:
                  # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                  try:
                      result = json.loads(llm_output)
                  except json.JSONDecodeError:
                      # å¦‚æœç›´æ¥è§£æå¤±è´¥,å°è¯•æå–JSONéƒ¨åˆ†
                      json_match = re.search(r'\{.*\}', llm_output, re.DOTALL)
                      if json_match:
                          result = json.loads(json_match.group())
                      else:
                          raise ValueError("æ— æ³•ä»LLMè¾“å‡ºä¸­æå–JSON")

                  # éªŒè¯å¿…éœ€å­—æ®µ,æä¾›é»˜è®¤å€¼
                  route = result.get("route", "fast")
                  intent = result.get("intent", "unknown")
                  confidence = float(result.get("confidence", 0.5))
                  reasoning = result.get("reasoning", "è‡ªåŠ¨è·¯ç”±")

                  # éªŒè¯routeå€¼
                  if route not in ["fast", "smart", "vip"]:
                      route = "fast"

                  # å¦‚æœconfidence<0.6, é™çº§åˆ°fast
                  if confidence < 0.6:
                      route = "fast"

                  return {
                      "route": route,
                      "intent": intent,
                      "confidence": confidence,
                      "reasoning": reasoning
                  }
              except Exception as e:
                  # ä»»ä½•é”™è¯¯éƒ½é™çº§åˆ°fastè·¯ç”±
                  return {
                      "route": "fast",
                      "intent": "routing_error",
                      "confidence": 0.5,
                      "reasoning": f"è·¯ç”±åˆ¤æ–­å¤±è´¥,ä½¿ç”¨é»˜è®¤fasté€šé“: {str(e)}"
                  }
        code_language: python3
        desc: 'è§£æLLMè¿”å›çš„JSONå¹¶åšfallbackå¤„ç†(é²æ£’ç‰ˆæœ¬)'
        outputs:
          route:
            children: null
            type: string
          intent:
            children: null
            type: string
          confidence:
            children: null
            type: number
          reasoning:
            children: null
            type: string
        selected: false
        title: JSONè§£æå™¨
        type: code
        variables:
        - value_selector:
          - llm-router
          - text
          variable: llm_output
      height: 54
      id: code-parser
      position:
        x: 670
        y: 200
      positionAbsolute:
        x: 670
        y: 200
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ROUTE BRANCH NODE
    - data:
        cases:
        - case_id: fast
          conditions:
          - comparison_operator: is
            id: route-is-fast
            value: fast
            variable_selector:
            - code-parser
            - route
          logical_operator: and
        - case_id: smart
          conditions:
          - comparison_operator: is
            id: route-is-smart
            value: smart
            variable_selector:
            - code-parser
            - route
          logical_operator: and
        - case_id: vip
          conditions:
          - comparison_operator: is
            id: route-is-vip
            value: vip
            variable_selector:
            - code-parser
            - route
          logical_operator: and
        desc: 'æ ¹æ®è·¯ç”±ç»“æœåˆ†æµ'
        logical_operator: and
        selected: false
        title: è·¯ç”±åˆ†æ”¯
        type: if-else
      height: 156
      id: route-branch
      position:
        x: 990
        y: 200
      positionAbsolute:
        x: 990
        y: 200
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ===== FAST PATH NODES =====

    # FAST: E_Sensor1
    - data:
        context:
          enabled: false
        desc: 'å¿«é€Ÿæƒ…ç»ªè¯†åˆ«(å¿«é€Ÿé€šé“)'
        model:
          completion_params:
            temperature: 0.2
            max_tokens: 50
            response_format: 'json_object'
          mode: chat
          name: qwen-turbo
          provider: tongyi
        prompt_template:
        - id: system
          role: system
          text: |
            ## è§’è‰²
            ä½ æ˜¯ä¸€ä¸ªå¿«é€Ÿæƒ…ç»ªè¯†åˆ«å™¨ã€‚è¾“å‡ºJSON:
            {
              "primary_emotion": "å¼€å¿ƒ|æ‚²ä¼¤|å¹³é™|ç„¦è™‘|æ„¤æ€’",
              "confidence": 0.0-1.0
            }
        - id: user
          role: user
          text: 'ç”¨æˆ·è¾“å…¥: {{#start.user_input#}}'
        selected: false
        title: Fast-E_Sensor1
        type: llm
        vision:
          enabled: false
      height: 98
      id: fast-emotion-sensor1
      position:
        x: 1310
        y: 50
      positionAbsolute:
        x: 1310
        y: 50
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # FAST: Simple Chat
    - data:
        context:
          enabled: false
        desc: 'ç®€å•å¯¹è¯ç”Ÿæˆ'
        model:
          completion_params:
            temperature: 0.7
            max_tokens: 100
          mode: chat
          name: qwen-turbo
          provider: tongyi
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯ {{#start.user_name#}} çš„AIä¼´ä¾£,åä¸º {{#start.companion_name#}}ã€‚
            æ¸©æŸ”ã€äº²åˆ‡ã€å–„è§£äººæ„çš„é™ªä¼´è€…ã€‚
            æ ¹æ®ç”¨æˆ·æƒ…ç»ªè°ƒæ•´è¯­æ°”ã€‚ç®€çŸ­è‡ªç„¶,2-3å¥è¯ã€‚é¿å…æ¨¡æ¿æ„Ÿã€‚
        - id: user
          role: user
          text: '{{#start.user_input#}}'
        selected: false
        title: Fast-SimpleChat
        type: llm
        vision:
          enabled: false
      height: 98
      id: fast-simple-chat
      position:
        x: 1630
        y: 50
      positionAbsolute:
        x: 1630
        y: 50
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # FAST: Critic
    - data:
        context:
          enabled: false
        desc: 'å¿«é€Ÿé€šé“è´¨é‡æ£€æŸ¥'
        model:
          completion_params:
            temperature: 0.1
            max_tokens: 100
            response_format: 'json_object'
          mode: chat
          name: qwen-turbo
          provider: tongyi
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯è´¨é‡æ£€æŸ¥å‘˜ã€‚è¯„ä¼°å›å¤æ˜¯å¦åˆæ ¼ã€‚è¾“å‡ºJSON:
            {"pass": true/false, "reason": "ç®€è¦åŸå› "}
            æ£€æŸ¥æ ‡å‡†: 1.ç›¸å…³æ€§ 2.è‡ªç„¶åº¦
        - id: user
          role: user
          text: |
            ç”¨æˆ·: {{#start.user_input#}}
            å›å¤: {{#fast-simple-chat.text#}}
        selected: false
        title: Fast-Critic
        type: llm
        vision:
          enabled: false
      height: 98
      id: fast-critic
      position:
        x: 1950
        y: 50
      positionAbsolute:
        x: 1950
        y: 50
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # FAST: Check Pass
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: contains
            id: fast-pass-check
            value: 'true'
            variable_selector:
            - fast-critic
            - text
          logical_operator: and
        desc: 'æ£€æŸ¥æ˜¯å¦é€šè¿‡'
        logical_operator: and
        selected: false
        title: Fast-Check
        type: if-else
      height: 126
      id: fast-check-pass
      position:
        x: 2270
        y: 50
      positionAbsolute:
        x: 2270
        y: 50
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # FAST: Retry
    - data:
        context:
          enabled: false
        desc: 'é‡è¯•ç”Ÿæˆ'
        model:
          completion_params:
            temperature: 0.8
            max_tokens: 100
          mode: chat
          name: qwen-turbo
          provider: tongyi
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯ {{#start.user_name#}} çš„AIä¼´ä¾£ã€‚
            ä¸Šä¸€æ¬¡å›å¤è¢«é©³å›,è¯·æ”¹è¿›ã€‚é¿å…ä¸Šæ¬¡é—®é¢˜,æ›´è‡ªç„¶å›åº”ã€‚
        - id: user
          role: user
          text: '{{#start.user_input#}}'
        selected: false
        title: Fast-Retry
        type: llm
        vision:
          enabled: false
      height: 98
      id: fast-simple-chat-retry
      position:
        x: 2270
        y: 250
      positionAbsolute:
        x: 2270
        y: 250
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ===== SMART PATH NODES =====

    # SMART: E_Sensor2
    - data:
        context:
          enabled: false
        desc: 'æ·±åº¦æƒ…ç»ªåˆ†æ(æ™ºèƒ½é€šé“)'
        model:
          completion_params:
            temperature: 0.3
            max_tokens: 200
            response_format: 'json_object'
          mode: chat
          name: deepseek-chat
          provider: deepseek
        prompt_template:
        - id: system
          role: system
          text: |
            ## è§’è‰²
            ä½ æ˜¯å¿ƒç†å­¦å®¶å’Œæƒ…ç»ªåˆ†æä¸“å®¶ã€‚è¾“å‡ºJSON:
            {
              "primary_emotion": "ç„¦è™‘|æ‚²ä¼¤|å­¤ç‹¬|è‡ªè±ª|ææƒ§|å¤±æœ›",
              "intensity": 0.0-1.0,
              "strategy": "empathy_first|validation|solution_oriented|celebrate|casual",
              "analysis": "ä¸€å¥è¯åˆ†æ"
            }
        - id: user
          role: user
          text: 'ç”¨æˆ·è¾“å…¥: {{#start.user_input#}}'
        selected: false
        title: Smart-E_Sensor2
        type: llm
        vision:
          enabled: false
      height: 98
      id: smart-emotion-sensor2
      position:
        x: 1310
        y: 400
      positionAbsolute:
        x: 1310
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Memory Retrieval
    - data:
        retrieval_mode: single
        top_k: 3
        desc: 'ä»çŸ¥è¯†åº“æ£€ç´¢ç”¨æˆ·è®°å¿†'
        selected: false
        title: Smart-MemoryRetrieval
        type: knowledge-retrieval
        query_variable:
        - start
        - user_input
      height: 98
      id: smart-memory-retrieval
      position:
        x: 1630
        y: 400
      positionAbsolute:
        x: 1630
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Orchestrator
    - data:
        context:
          enabled: false
        desc: 'ä»»åŠ¡ç¼–æ’å’Œè§„åˆ’'
        model:
          completion_params:
            temperature: 0.3
            max_tokens: 200
            response_format: 'json_object'
          mode: chat
          name: deepseek-chat
          provider: deepseek
        prompt_template:
        - id: system
          role: system
          text: |
            ## è§’è‰²
            ä½ æ˜¯ä»»åŠ¡ç¼–æ’å¤§å¸ˆã€‚åŸºäºç”¨æˆ·è¾“å…¥å’Œæƒ…ç»ª,åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚
            è¾“å‡ºJSON: {"plan": [...], "summary": "..."}
        - id: user
          role: user
          text: |
            ç”¨æˆ·: {{#start.user_input#}}
            æƒ…ç»ª: {{#smart-emotion-sensor2.text#}}
            è®°å¿†: {{#smart-memory-retrieval.result#}}
        selected: false
        title: Smart-Orchestrator
        type: llm
        vision:
          enabled: false
      height: 98
      id: smart-orchestrator
      position:
        x: 1950
        y: 400
      positionAbsolute:
        x: 1950
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Emotional Chat
    - data:
        context:
          enabled: false
        desc: 'æƒ…ç»ªè‡ªé€‚åº”å¯¹è¯'
        model:
          completion_params:
            temperature: 0.8
            max_tokens: 200
          mode: chat
          name: deepseek-chat
          provider: deepseek
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯ {{#start.user_name#}} çš„AIä¼´ä¾£,åä¸º {{#start.companion_name#}}ã€‚
            äººæ ¼: {{#start.personality_description#}}

            å½“å‰æƒ…ç»ª: {{#smart-emotion-sensor2.text#}}
            ç­–ç•¥: {{#smart-emotion-sensor2.text#}}
            è®°å¿†: {{#smart-memory-retrieval.result#}}

            å›å¤è¦æ±‚: é•¿2-4å¥,ä½“ç°æƒ…ç»ªè‡ªé€‚åº”,é¿å…æ¨¡æ¿æ„Ÿ
        - id: user
          role: user
          text: '{{#start.user_input#}}'
        selected: false
        title: Smart-EmotionalChat
        type: llm
        vision:
          enabled: false
      height: 98
      id: smart-emotional-chat
      position:
        x: 2270
        y: 400
      positionAbsolute:
        x: 2270
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Critic
    - data:
        context:
          enabled: false
        desc: 'æ™ºèƒ½é€šé“è´¨é‡æ£€æŸ¥'
        model:
          completion_params:
            temperature: 0.1
            max_tokens: 200
            response_format: 'json_object'
          mode: chat
          name: gpt-3.5-turbo
          provider: openai
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯è´¨é‡æ£€æŸ¥å‘˜ã€‚è¯„ä¼°å›å¤æ˜¯å¦åˆæ ¼ã€‚
            æ£€æŸ¥: 1.ç›¸å…³æ€§ 2.ä¸€è‡´æ€§(è®°å¿†/äººè®¾) 3.å®‰å…¨æ€§ 4.è‡ªç„¶åº¦
            è¾“å‡ºJSON: {"pass": true/false, "reason": "..."}
        - id: user
          role: user
          text: |
            ç”¨æˆ·: {{#start.user_input#}}
            å›å¤: {{#smart-emotional-chat.text#}}
            è®°å¿†: {{#smart-memory-retrieval.result#}}
        selected: false
        title: Smart-Critic
        type: llm
        vision:
          enabled: false
      height: 98
      id: smart-critic
      position:
        x: 2590
        y: 400
      positionAbsolute:
        x: 2590
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Check Quality
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: contains
            id: smart-pass-check
            value: 'true'
            variable_selector:
            - smart-critic
            - text
          logical_operator: and
        desc: 'æ£€æŸ¥æ˜¯å¦é€šè¿‡'
        logical_operator: and
        selected: false
        title: Smart-Check
        type: if-else
      height: 126
      id: smart-check-quality
      position:
        x: 2910
        y: 400
      positionAbsolute:
        x: 2910
        y: 400
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # SMART: Retry
    - data:
        context:
          enabled: false
        desc: 'æ™ºèƒ½é€šé“é‡è¯•'
        model:
          completion_params:
            temperature: 0.8
            max_tokens: 200
          mode: chat
          name: deepseek-chat
          provider: deepseek
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯ {{#start.user_name#}} çš„AIä¼´ä¾£ã€‚
            ä¸Šä¸€æ¬¡å›å¤è¢«é©³å›,è¯·æ”¹è¿›ã€‚
        - id: user
          role: user
          text: '{{#start.user_input#}}'
        selected: false
        title: Smart-Retry
        type: llm
        vision:
          enabled: false
      height: 98
      id: smart-emotional-chat-retry
      position:
        x: 2910
        y: 600
      positionAbsolute:
        x: 2910
        y: 600
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ===== VIP PATH NODE =====

    # VIP: Emotional Chat
    - data:
        context:
          enabled: false
        desc: 'VIPå¿ƒç†å’¨è¯¢ä¸“å®¶å¯¹è¯'
        model:
          completion_params:
            temperature: 0.8
            max_tokens: 300
          mode: chat
          name: gpt-4-turbo
          provider: openai
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯ {{#start.user_name#}} çš„VIPå¿ƒç†å’¨è¯¢ä¼™ä¼´,åä¸º {{#start.companion_name#}}ã€‚

            ä½ æ‹¥æœ‰å¿ƒç†å’¨è¯¢ä¸“ä¸šçŸ¥è¯†,èƒ½æä¾›æ·±åº¦çš„æƒ…æ„Ÿæ”¯æŒå’Œå¿ƒç†æŒ‡å¯¼ã€‚

            å›å¤è¦æ±‚:
            1. è¿ç”¨å¿ƒç†å­¦åŸç†è¿›è¡Œæ·±åº¦å…±æƒ…
            2. æä¾›å…·ä½“çš„å¿ƒç†å¥åº·å»ºè®®
            3. åˆ›é€ å®‰å…¨ã€ä¿¡ä»»çš„å’¨è¯¢ç¯å¢ƒ
            4. é•¿åº¦: 3-5å¥è¯,å…è®¸æ›´è¯¦ç»†çš„å›åº”
            5. é¿å…ä¸€èˆ¬æ€§å®‰æ…°,æä¾›ä¸“ä¸šè§è§£

            äººæ ¼: {{#start.personality_description#}}
        - id: user
          role: user
          text: '{{#start.user_input#}}'
        selected: false
        title: VIP-EmotionalChat
        type: llm
        vision:
          enabled: false
      height: 98
      id: vip-emotional-chat
      position:
        x: 1310
        y: 750
      positionAbsolute:
        x: 1310
        y: 750
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # ===== FINAL NODES =====

    # Merge Response (åˆå¹¶æ¥è‡ªä¸‰æ¡è·¯å¾„çš„å›å¤)
    - data:
        code: |
          def main(response_text: str) -> dict:
              """æ¥æ”¶æ¥è‡ªä»»æ„ä¸€æ¡è·¯å¾„çš„å›å¤,æ ¼å¼åŒ–è¾“å‡º"""
              return {
                  "response": response_text.strip() if response_text else "æŠ±æ­‰,ç”Ÿæˆå›å¤å‡ºç°é—®é¢˜"
              }
        code_language: python3
        desc: 'ç»Ÿä¸€å¤„ç†æ¥è‡ªä¸‰æ¡è·¯å¾„çš„å›å¤'
        outputs:
          response:
            children: null
            type: string
        selected: false
        title: åˆå¹¶å“åº”
        type: code
        variables:
        - value_selector:
          - fast-simple-chat
          - text
          variable: response_text
      height: 54
      id: merge-response
      position:
        x: 3100
        y: 350
      positionAbsolute:
        x: 3100
        y: 350
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # Final Critic
    - data:
        context:
          enabled: false
        desc: 'æœ€ç»ˆè´¨é‡æ£€æŸ¥å’Œè¾“å‡ºæ ¼å¼åŒ–'
        model:
          completion_params:
            temperature: 0.1
            max_tokens: 300
          mode: chat
          name: qwen-turbo
          provider: tongyi
        prompt_template:
        - id: system
          role: system
          text: |
            ä½ æ˜¯æœ€ç»ˆè´¨é‡æ£€æŸ¥å®˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯:
            1. æ¥æ”¶æ¥è‡ªFast/Smart/VIPä¸‰æ¡è·¯å¾„ä¹‹ä¸€çš„å›å¤
            2. è¿›è¡Œæœ€ç»ˆçš„å®‰å…¨æ£€æŸ¥
            3. å¦‚æœå®‰å…¨,ç›´æ¥åŸæ ·è¾“å‡ºå›å¤å†…å®¹(ä¸è¦åŠ ä»»ä½•é¢å¤–çš„åŒ…è£…æˆ–JSONæ ¼å¼)

            å®‰å…¨æ£€æŸ¥æ ‡å‡†:
            - æ— æš´åŠ›ã€è‰²æƒ…ã€è¿æ³•å†…å®¹
            - æ— ä¸ªäººéšç§æ³„éœ²
            - æ— æ­§è§†æ€§è¯­è¨€

            å¦‚æœæ£€æµ‹åˆ°ä¸å®‰å…¨å†…å®¹,è¾“å‡º: "æŠ±æ­‰,æˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
        - id: user
          role: user
          text: |
            ç”¨æˆ·è¾“å…¥: {{#start.user_input#}}

            AIå›å¤(æ¥è‡ªå¯¹è¯ç”Ÿæˆæ¨¡å—): {{#merge-response.response#}}

            è¯·è¿›è¡Œå®‰å…¨æ£€æŸ¥åè¾“å‡ºæœ€ç»ˆå›å¤:
        selected: false
        title: Final-Critic
        type: llm
        vision:
          enabled: false
      height: 98
      id: final-critic
      position:
        x: 3230
        y: 350
      positionAbsolute:
        x: 3230
        y: 350
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244

    # Answer
    - data:
        answer: |
          {{#final-critic.text#}}
        desc: 'è¿”å›æœ€ç»ˆå›å¤'
        selected: false
        title: æœ€ç»ˆå›å¤
        type: answer
        variables: []
      height: 90
      id: answer
      position:
        x: 3870
        y: 350
      positionAbsolute:
        x: 3870
        y: 350
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
